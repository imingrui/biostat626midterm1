# Load Packages
library(tidyverse)
library(glmnet)
library(caret)
library(doMC)

# Import Data
train = read.table('~/desktop/626 mid1/data/training_data.txt',header = T)
test = read.table('~/desktop/626 mid1/data/test_data.txt',header = T)

train = train %>% 
  select(-subject) %>% 
  mutate(activity = ifelse(activity %in% 7:12,7,activity),
         activity = as.factor(activity))

test = test %>% 
  select(-subject)

table(train$activity)

# PCA
PCA = prcomp(x = train %>% select(-activity))
lambda = PCA$sdev^2
prop = cumsum(lambda)/sum(lambda)
n_pc = min(which(prop>0.8))
PCA$x[,1:2] %>% 
  as.data.frame() %>% 
  mutate(activity = train$activity) %>% 
  ggplot(aes(x = PC1,y = PC2,color = activity)) +
  geom_point() +
  scale_color_brewer(palette = 'Set1') +
  theme_bw()

#### Lasso ####
x_train = train %>% select(-activity) %>% as.matrix()
y_train = train$activity
x_test = test %>% as.matrix()
set.seed(1)
registerDoMC(6)
cv_lasso = cv.glmnet(x = x_train,
                     y = y_train,
                     family = 'multinomial',
                     type.measure = 'class',
                     alpha = 1,
                     parallel = T)
plot(cv_lasso)                     

var_lasso1 = coef(cv_lasso)[[1]] %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = 'variable') %>% 
  slice(-1) %>% 
  filter(`1`!=0) %>% 
  pull(variable)

var_lasso2 = coef(cv_lasso)[[2]] %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = 'variable') %>% 
  slice(-1) %>% 
  filter(`1`!=0) %>% 
  pull(variable)

var_lasso3 = coef(cv_lasso)[[3]] %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = 'variable') %>% 
  slice(-1) %>% 
  filter(`1`!=0) %>% 
  pull(variable)

var_lasso4 = coef(cv_lasso)[[4]] %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = 'variable') %>% 
  slice(-1) %>% 
  filter(`1`!=0) %>% 
  pull(variable)

var_lasso5 = coef(cv_lasso)[[5]] %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = 'variable') %>% 
  slice(-1) %>% 
  filter(`1`!=0) %>% 
  pull(variable)

var_lasso6 = coef(cv_lasso)[[6]] %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = 'variable') %>% 
  slice(-1) %>% 
  filter(`1`!=0) %>% 
  pull(variable)

var_lasso7 = coef(cv_lasso)[[7]] %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = 'variable') %>% 
  slice(-1) %>% 
  filter(`1`!=0) %>% 
  pull(variable)

var_lasso = c(var_lasso1,var_lasso2,var_lasso3,var_lasso4,var_lasso5,var_lasso6,var_lasso7)
var_lasso = unique(var_lasso)
pre_lasso = predict(cv_lasso,newx = x_test,s = cv_lasso$lambda.1se,type = 'class')
pre_lasso = as.numeric(pre_lasso)
# final_train = train %>% select(activity,all_of(var_lasso))
####################################

final_train = PCA$x[,1:n_pc] %>% as.data.frame() %>% mutate(activity = train$activity)
final_test = predict(PCA,newdata = test)
final_test = as.data.frame(final_test[,1:n_pc])

set.seed(1)
my_control = trainControl(method = 'repeatedcv',
                          number = 5,
                          repeats = 10,
                          search = 'random')
f = as.formula('activity~.')

# Random Forest
set.seed(1)
registerDoMC(6)
cv_RF = train(f,
              data = final_train,
              method = 'rf',
              metric = 'Accuracy',
              trControl = my_control,
              tuneLength = 30)
cv_RF$results
plot(cv_RF)

set.seed(1)
registerDoMC(6)
final_RF = train(f,
                 data = final_train,
                 method = 'rf',
                 tuneGrid = cv_RF$bestTune)
pre_RF = predict(final_RF,newdata = final_test)

# XGBoost
set.seed(1)
registerDoMC(6)
cv_XGBoost = train(f,
                   data = final_train,
                   method = 'xgbTree',
                   metric = 'Accuracy',
                   trControl = my_control,
                   tuneLength = 30)
cv_XGBoost$results

set.seed(1)
registerDoMC(6)
final_XGBoost = train(f,
                      data = final_train,
                      method = 'xgbTree',
                      tuneGrid = cv_XGBoost$bestTune)
pre_XGBoost = predict(final_XGBoost,newdata = final_test)

# SVM
set.seed(1)
registerDoMC(6)
cv_SVM = train(f,
               data = final_train,
               method = 'svmRadial',
               metric = 'Accuracy',
               trControl = my_control,
               tuneLength = 30)
cv_SVM$results

set.seed(1)
registerDoMC(6)
final_SVM = train(f,
                  data = final_train,
                  method = 'svmRadial',
                  tuneGrid = cv_SVM$bestTune)
pre_SVM = predict(final_SVM,newdata = final_test)

# Neural Network

set.seed(1)
registerDoMC(6)
cv_NNET = train(f,
                data = final_train,
                method = 'nnet',
                trace = F,
                metric = 'Accuracy',
                trControl = my_control,
                tuneLength = 30)
cv_NNET$results

set.seed(1)
registerDoMC(6)
final_NNET = train(f,
                   data = final_train,
                   method = 'nnet',
                   trace = F,
                   tuneGrid = cv_NNET$bestTune)
pre_NNET = predict(final_NNET,newdata = final_test)

tibble(Lasso = 1-min(cv_lasso$cvm),
       `Random Forest` = max(cv_RF$results$Accuracy),
       XGBoost = max(cv_XGBoost$results$Accuracy),
       SVM = max(cv_SVM$results$Accuracy),
       `Neural Network` = max(cv_NNET$results$Accuracy)) %>% 
  pivot_longer(cols = everything(),
               names_to = 'Algorithm',
               values_to = 'CV Accuracy')











